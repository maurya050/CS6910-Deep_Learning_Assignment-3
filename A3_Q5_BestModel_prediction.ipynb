{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b174k4USt_Pn"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import torch\n",
        "import heapq\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt55\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.ticker as ticker\n",
        "from collections import defaultdict\n",
        "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiXlgaH-uU6N",
        "outputId": "136448f3-a3d6-49bb-9196-cfe9cadad338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# to mount to the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgCR_YrSuWlc",
        "outputId": "aea4d714-2756-47aa-87d3-b1dd7be8e0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/aksharantar_dataset/tel\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/aksharantar_dataset/tel/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1tF66fD2wNpb"
      },
      "outputs": [],
      "source": [
        "val_tsv_file = open(\"/content/drive/MyDrive/aksharantar_dataset/tel/tel_valid.csv\")\n",
        "tsv_file = open(\"/content/drive/MyDrive/aksharantar_dataset/tel/tel_train.csv\")\n",
        "test_tsv_file = open(\"/content/drive/MyDrive/aksharantar_dataset/tel/tel_test.csv\")\n",
        "val_read_tsv = csv.reader(val_tsv_file)\n",
        "read_tsv = csv.reader(tsv_file)\n",
        "test_read_tsv = csv.reader(test_tsv_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_pad, _space = \"\\t\", \"\\n\"\n",
        "train_X, train_Y = [], []\n",
        "for i in read_tsv:   \n",
        "    train_Y.append(i[1])\n",
        "    train_X.append(i[0])\n",
        "\n",
        "test_Y, test_X = [], []\n",
        "for i in test_read_tsv:\n",
        "    test_Y.append(i[1])\n",
        "    test_X.append(i[0])\n",
        "\n",
        "val_X, val_Y = [], []\n",
        "for i in val_read_tsv:\n",
        "    val_Y.append(i[1])\n",
        "    val_X.append(i[0])\n",
        "\n",
        "\n",
        "trainsize=len(train_X)"
      ],
      "metadata": {
        "id": "03zNG6ha7ZoY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xAeheagXzabj"
      },
      "outputs": [],
      "source": [
        "train_X, train_Y = np.array(train_X), np.array(train_Y)\n",
        "for i in range(train_Y.shape[0]):\n",
        "    train_Y[i] = _pad + train_Y[i] + _space\n",
        "\n",
        "test_X, test_Y = np.array(test_X), np.array(test_Y)\n",
        "for i in range(test_Y.shape[0]):\n",
        "    test_Y[i] = _pad + test_Y[i] + _space\n",
        "\n",
        "val_X, val_Y = np.array(val_X), np.array(val_Y)\n",
        "for i in range(val_Y.shape[0]):\n",
        "    val_Y[i] = _pad + val_Y[i] + _space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nj7PZAZtv-Dn"
      },
      "outputs": [],
      "source": [
        "val_output_corpus, output_corpus, val_input_corpus, input_corpus = set(), set(), set(), set()\n",
        "d_type, td_type, c_end = \"int64\", torch.int64, \" \"\n",
        "output_corpus, input_corpus = set(char for word in train_Y for char in word if char not in output_corpus), set(char for word in train_X for char in word if char not in input_corpus)\n",
        "\n",
        "input_corpus.add(c_end)\n",
        "output_corpus.add(c_end)\n",
        "\n",
        "output_corpus, input_corpus = sorted(list(output_corpus)),  sorted(list(input_corpus))\n",
        "num_decoder_tokens, num_encoder_tokens = len(output_corpus),  len(input_corpus)\n",
        "\n",
        "max_decoder_seq_length, max_encoder_seq_length = max([len(txt) for txt in train_Y]), max([len(txt) for txt in train_X]) + 2\n",
        "val_output_corpus, val_input_corpus = set(char for word in val_Y for char in word if char not in val_output_corpus), set(char for word in val_X for char in word if char not in val_input_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)"
      ],
      "metadata": {
        "id": "52WUkwQMfHAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7364311a-4ddb-4b18-98df-23fdb97783b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sequence length for outputs: 21\n",
            "Number of unique output tokens: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ln_train, ln_val = len(train_X), len(val_X)\n",
        "print(\"Number of samples:\", len(train_X))\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)"
      ],
      "metadata": {
        "id": "SJkxFEzrAydF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64222227-3c71-447f-a063-2347c7d1cb5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 51200\n",
            "Max sequence length for inputs: 30\n",
            "Number of unique input tokens: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = np.zeros((max_encoder_seq_length,ln_train), dtype= d_type)\n",
        "target_data = np.zeros((max_decoder_seq_length,ln_train), dtype= d_type)\n",
        "input_data_val = np.zeros((max_encoder_seq_length,ln_val), dtype= d_type)\n",
        "target_data_val = np.zeros((max_decoder_seq_length,ln_val), dtype= d_type)"
      ],
      "metadata": {
        "id": "zWgzRQmO_niy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5_dcaF7Bv-Kt"
      },
      "outputs": [],
      "source": [
        "input_size_decoder = num_decoder_tokens\n",
        "output_size = num_decoder_tokens\n",
        "input_size_encoder = num_encoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TN361UA8uUFS"
      },
      "outputs": [],
      "source": [
        "def create_char_index(corpus):\n",
        "    char_index = defaultdict(int)\n",
        "    for i, char in enumerate(corpus):\n",
        "        ind_ = i\n",
        "        if char not in char_index:\n",
        "            char_index[char] = ind_\n",
        "    return dict(char_index)\n",
        "\n",
        "output_char_index, input_char_index = create_char_index(output_corpus), create_char_index(input_corpus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wFQQcOvjySop"
      },
      "outputs": [],
      "source": [
        "for i in range(ln_train):\n",
        "    y , x, count, count1 = train_Y[i], train_X[i], 0, 1\n",
        "    for t, char in enumerate(x):\n",
        "        input_data[t, i] = input_char_index[char]\n",
        "    t_z = t+1\n",
        "    input_data[t_z :,i], count = input_char_index[c_end], count + 1 \n",
        "\n",
        "    for t, char in enumerate(y):\n",
        "        target_data[t, i] = output_char_index[char]\n",
        "        count1 = count+1  \n",
        "    t_z = t+1       \n",
        "    target_data[t_z :,i] = output_char_index[c_end]\n",
        "    \n",
        "for i in range(ln_val):\n",
        "    y, x, count = val_Y[i], val_X[i], 0\n",
        "    for t, char in enumerate(x):\n",
        "        input_data_val[t, i], count = input_char_index[char], count +1\n",
        "    t_z = t+1\n",
        "    input_data_val[t_z :,i] = input_char_index[c_end]\n",
        "    \n",
        "    count = 0\n",
        "    for t, char in enumerate(y):\n",
        "        target_data_val[t, i], count = output_char_index[char], count +1\n",
        "    t_z = t+1        \n",
        "    target_data_val[t_z :,i] = output_char_index[c_end]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vBgvvg73t_Ps"
      },
      "outputs": [],
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "input_data, input_data_val, target_data, target_data_val = torch.tensor(input_data,dtype = td_type), torch.tensor(input_data_val,dtype = td_type), torch.tensor(target_data,dtype = td_type), torch.tensor(target_data_val,dtype = td_type)\n",
        "reverse_input_char_index = {i: char for char, i in input_char_index.items()}\n",
        "reverse_target_char_index = {i: char for char, i in output_char_index.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aq0GGXSMt_Pu"
      },
      "outputs": [],
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index, reverse_target_char_index = dict((i, char) for char, i in input_char_index.items()), dict((i, char) for char, i in output_char_index.items())\n",
        "input_size_decoder, output_size, input_size_encoder = num_decoder_tokens, num_decoder_tokens, num_encoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C9Rp1uett_Pv"
      },
      "outputs": [],
      "source": [
        "class DecoderGRU(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout):\n",
        "        super(DecoderGRU, self).__init__()\n",
        "        drop_par, emb_size = dropout, embedding_size\n",
        "        self.dropout = nn.Dropout(drop_par)\n",
        "        self.num_layers, self.hidden_size, inp = num_layers, hidden_size, input_size\n",
        "        gru_par = hidden_size * 2 + emb_size\n",
        "        self.embedding = nn.Embedding(inp, emb_size)\n",
        "        self.rnn = nn.GRU(gru_par, hidden_size, num_layers)\n",
        "        lin_par, s_dim = hidden_size * 3, 0\n",
        "        self.energy = nn.Linear(lin_par, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim = s_dim)\n",
        "        self.relu = nn.Hardshrink()\n",
        "\n",
        "    def forward(self, x, encoder_states, hidden):\n",
        "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
        "        # is 1 here because we are sending in a single word and not a sentence\n",
        "        x = x.unsqueeze(0)\n",
        "        drop_par, sequence_length = self.embedding(x), encoder_states.shape[0]\n",
        "        r_dim = 2\n",
        "        embedding = self.dropout(drop_par)\n",
        "        # embedding shape: (1, N, embedding_size)\n",
        "        \n",
        "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
        "        # h_reshaped: (seq_length, N, hidden_size*2)\n",
        "        relu_par = torch.cat((h_reshaped, encoder_states), dim = r_dim)\n",
        "        energy = self.relu(self.energy(relu_par))\n",
        "        # energy: (seq_length, N, 1)\n",
        "        \n",
        "        attention = self.softmax(energy)\n",
        "        # attention: (seq_length, N, 1)\n",
        "        encoder_states = encoder_states.permute(1,0,2)\n",
        "\n",
        "        attention = attention.permute(1,2,0)\n",
        "        # attention: (N, seq_length, 1)\n",
        "        encoder_states = self.relu(encoder_states)\n",
        "        # encoder_states: (N, seq_length, hidden_size*2)\n",
        "        context_init = torch.bmm(attention, encoder_states)\n",
        "        context_vector = context_init.permute(1,0,2)\n",
        "        \n",
        "        rnn_input = torch.cat((context_vector, self.dropout(drop_par)),dim = r_dim)\n",
        "       # rnn_input = self.relu(rnn_input)\n",
        "        outputs, (hidden) = self.rnn(rnn_input, (hidden))\n",
        "        # outputs shape: (1, N, hidden_size)\n",
        "\n",
        "        #predictions = self.fc(outputs)\n",
        "\n",
        "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
        "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
        "        # just gonna remove the first dim\n",
        "        predictions = self.fc(outputs).squeeze(0)\n",
        "\n",
        "        return predictions, hidden, attention\n",
        "class Seq2SeqGR(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2SeqGR, self).__init__()\n",
        "        self.decoder, self.encoder = decoder, encoder\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "        target_len, target_vocab_size, batch_size = target.shape[0], num_decoder_tokens, source.shape[1]\n",
        "        \n",
        "        encoder_states, hidden = self.encoder(source)\n",
        "\n",
        "         # Grab the first input to the Decoder which will be <SOS> token\n",
        "        n_len, x = target.shape[0], target[0]\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "        for t in range(1, n_len):\n",
        "            # Use previous hidden, cell as context from encoder at start\n",
        "            output, hidden, _ = self.decoder(x, encoder_states, hidden)\n",
        "\n",
        "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
        "            best_guess, ind = output.argmax(1), t\n",
        "\n",
        "            # Store next output prediction\n",
        "            outputs[ind] = output\n",
        "\n",
        "            x = best_guess if random.random() >= teacher_force_ratio else target[t]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class EncoderGRU(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout):\n",
        "        super(EncoderGRU, self).__init__()\n",
        "        drop_par, emb_size, bidir = dropout, embedding_size, True\n",
        "        self.dropout = nn.Dropout(drop_par)\n",
        "        self.num_layers, self.hidden_size, inp = num_layers, hidden_size, input_size\n",
        "        self.embedding = nn.Embedding(inp, emb_size)\n",
        "        fc_lin_par = hidden_size * 2\n",
        "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, bidirectional = bidir)\n",
        "        \n",
        "        self.fc_hidden = nn.Linear(fc_lin_par, hidden_size)\n",
        "        self.fc_cell = nn.Linear(fc_lin_par, hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (seq_length, N) where N is batch size\n",
        "        drop_par, fc_dim  = self.embedding(x), 2\n",
        "        embedding = self.dropout(drop_par)\n",
        "        # embedding shape: (seq_length, N, embedding_size)\n",
        "        \n",
        "        encoder_states, hidden = self.rnn(embedding)\n",
        "        # outputs shape: (seq_length, N, hidden_size)\n",
        "        fc_hidden_par = (hidden[0:1], hidden[1:2])\n",
        "        fc_par = torch.cat(fc_hidden_par, dim = fc_dim)\n",
        "        hidden = self.fc_hidden(fc_par)\n",
        "        #cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
        "\n",
        "        return encoder_states, hidden"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs, dec_dropout = 40, 0.3\n",
        "hidden_size, num_layers = 512, 1\n",
        "beam_width, learning_rate =4, 0.001\n",
        "batch_size, enc_dropout = 512, 0.1\n",
        "encoder_embedding_size, decoder_embedding_size = 256, 256\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "7A0oiPO4j7Cs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_findGR(model, word, norm,input_char_index, output_char_index, reverse_input_char_index,reverse_target_char_index, \n",
        "                max_encoder_seq_length, max_decoder_seq_length,num_encoder_tokens, num_decoder_tokens, beam_width, device, length_penalty=0.6):\n",
        "\n",
        "\n",
        "\n",
        "    word_val, word_t, attention, ln_word = 0, '', [], len(word)\n",
        "    data = np.zeros((max_encoder_seq_length, 1), dtype= d_type)\n",
        "    for t in range(ln_word):\n",
        "        char = word[t]\n",
        "        data[t, word_val] = input_char_index[char]\n",
        "    word_size = ln_word\n",
        "    data[ word_size:, word_val] = input_char_index[c_end]\n",
        "    data = torch.tensor(data, dtype= td_type).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_states,hidden = model.encoder(data)\n",
        "\n",
        "    # Initialize beam\n",
        "    \n",
        "    value,  _dim = 1, 0\n",
        "    initial_sequence = torch.tensor(np.array(output_char_index[_pad]).reshape(value,)).to(device)\n",
        "    beam, res = [(0.0, initial_sequence, hidden.unsqueeze(0))], hidden.unsqueeze(0) # [(score, sequence, hidden)]\n",
        "    best_res, _value = \"\", -1\n",
        "    for _ in range(max_decoder_seq_length):\n",
        "        options, candidates = [], []\n",
        "        for score, seq, hidden in beam:\n",
        "            last_token, count = seq[_value].item(), 0\n",
        "            _total = 0\n",
        "            if last_token == output_char_index[_space]:\n",
        "                # If the sequence ends with the end token, add it to the candidates\n",
        "                candidates.append((score, seq, hidden))\n",
        "                count, _total =count+1, _total+1\n",
        "                continue\n",
        "          \n",
        "            tempval, _total  = np.array(last_token).reshape(value,), 0\n",
        "            x = torch.tensor(tempval).to(device)\n",
        "            output, hidden,at = model.decoder(x,encoder_states ,hidden.squeeze(0))\n",
        "            attention.append(at.detach().cpu().numpy())\n",
        "            res, _total = output[0:], _total + count\n",
        "            probabilities = F.softmax(output, dim=1)\n",
        "            \n",
        "            # Get the top-k probabilities and tokens\n",
        "            topk_probs, topk_tokens = torch.topk(probabilities, k=beam_width)\n",
        "            topk, tops = topk_tokens[0], topk_probs[0]\n",
        "            result, _total, len_pen = probabilities, 0,  length_penalty\n",
        "            for prob, token in zip(tops, topk):\n",
        "                new_s, _dim = token.unsqueeze(0), 0\n",
        "                new_seq = torch.cat((seq, new_s), dim = _dim)\n",
        "                new_hidden = hidden.clone().unsqueeze(_dim)\n",
        "                penalty = len(new_seq) - 1\n",
        "                _score = score + torch.log(prob).item()\n",
        "                length_penalty_factor = ((penalty) / 5) **  len_pen\n",
        "                   # Adjust penalty factor as needed\n",
        "                candidates.append((_score / length_penalty_factor, new_seq, new_hidden))\n",
        "                options.append((_score / length_penalty_factor))\n",
        "        # Select top-k candidates based on the accumulated scores\n",
        "        beam = heapq.nlargest(beam_width, candidates, key=lambda x: x[_dim])\n",
        "\n",
        "    # Select the best sequence from the beam as the output\n",
        "    best_score, best_sequence, _ = max(beam, key=lambda x: x[_dim])\n",
        "    word_t = ''.join([reverse_target_char_index[token.item()] for token in best_sequence[value : _value]])\n",
        "    best_res = word_t\n",
        "\n",
        "    return word_t,attention\n"
      ],
      "metadata": {
        "id": "jR6cHspujCoF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0vTS0k5zt_Pz"
      },
      "outputs": [],
      "source": [
        "num_layers_dec, num_layers_enc, l_rate = 1, 1, learning_rate\n",
        "enc_embedding_size, hidden_size_enc = encoder_embedding_size, hidden_size\n",
        "dropout_dec, dropout_enc, dim_ = dec_dropout, enc_dropout, 1\n",
        "input_size_dec, input_size_enc = input_size_decoder, input_size_encoder\n",
        "hidden_size_dec, dec_embedding_size = hidden_size,  decoder_embedding_size\n",
        "\n",
        "\n",
        "encoder_net = EncoderGRU(input_size_enc,enc_embedding_size, hidden_size_enc, num_layers_enc, dropout_enc).to(device)\n",
        "decoder_net = DecoderGRU( input_size_dec,dec_embedding_size,hidden_size_dec,output_size,num_layers_dec,dropout_dec,).to(device)\n",
        "\n",
        "model = Seq2SeqGR(encoder_net, decoder_net).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = l_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vTPiTDyFSidb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9487e67-86f1-4535-ebd4-c1a8809d339a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0 / 40]\n",
            "0.095703125\n",
            "[Epoch 1 / 40]\n",
            "0.2626953125\n",
            "[Epoch 2 / 40]\n",
            "0.35888671875\n",
            "[Epoch 3 / 40]\n",
            "0.396240234375\n",
            "[Epoch 4 / 40]\n",
            "0.38525390625\n",
            "[Epoch 5 / 40]\n",
            "0.4423828125\n",
            "[Epoch 6 / 40]\n",
            "0.44384765625\n",
            "[Epoch 7 / 40]\n",
            "0.47119140625\n",
            "[Epoch 8 / 40]\n",
            "0.48193359375\n",
            "[Epoch 9 / 40]\n",
            "0.483642578125\n",
            "[Epoch 10 / 40]\n",
            "0.494873046875\n",
            "[Epoch 11 / 40]\n",
            "0.466552734375\n",
            "[Epoch 12 / 40]\n",
            "0.4677734375\n",
            "[Epoch 13 / 40]\n",
            "0.462890625\n",
            "[Epoch 14 / 40]\n",
            "0.46337890625\n",
            "[Epoch 15 / 40]\n",
            "0.48193359375\n",
            "[Epoch 16 / 40]\n",
            "0.461669921875\n",
            "[Epoch 17 / 40]\n",
            "0.480712890625\n",
            "[Epoch 18 / 40]\n",
            "0.498291015625\n",
            "[Epoch 19 / 40]\n",
            "0.494140625\n",
            "[Epoch 20 / 40]\n",
            "0.48388671875\n",
            "[Epoch 21 / 40]\n",
            "0.42578125\n",
            "[Epoch 22 / 40]\n",
            "0.455810546875\n",
            "[Epoch 23 / 40]\n",
            "0.4765625\n",
            "[Epoch 24 / 40]\n",
            "0.496826171875\n",
            "[Epoch 25 / 40]\n",
            "0.473876953125\n",
            "[Epoch 26 / 40]\n",
            "0.46923828125\n",
            "[Epoch 27 / 40]\n",
            "0.490234375\n",
            "[Epoch 28 / 40]\n",
            "0.4912109375\n",
            "[Epoch 29 / 40]\n",
            "0.49658203125\n",
            "[Epoch 30 / 40]\n",
            "0.49560546875\n",
            "[Epoch 31 / 40]\n",
            "0.515380859375\n",
            "[Epoch 32 / 40]\n",
            "0.49609375\n",
            "[Epoch 33 / 40]\n",
            "0.49755859375\n",
            "[Epoch 34 / 40]\n",
            "0.50634765625\n",
            "[Epoch 35 / 40]\n",
            "0.505126953125\n",
            "[Epoch 36 / 40]\n",
            "0.50048828125\n",
            "[Epoch 37 / 40]\n",
            "0.50146484375\n",
            "[Epoch 38 / 40]\n",
            "0.501708984375\n",
            "[Epoch 39 / 40]\n",
            "0.495361328125\n"
          ]
        }
      ],
      "source": [
        "train_ds_y, train_ds_x = torch.split(target_data,batch_size,dim = dim_), torch.split(input_data,batch_size, dim = dim_)\n",
        "count_ =0\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "    model.eval()\n",
        "    model.train()\n",
        "\n",
        "    for i, (x,y) in enumerate(zip(train_ds_x,train_ds_y)):\n",
        "        # Get input and targets and get to cuda\n",
        "        target, inp_data = y.to(device),  x.to(device)\n",
        "        count_ = count_ + 1\n",
        "        # Forward prop\n",
        "        output = model(inp_data, target)\n",
        "        target, output = target[1:].reshape(-1), output[1:].reshape(-1, output.shape[2])\n",
        "        optimizer.zero_grad()\n",
        "        loss, count_ = criterion(output, target), 0\n",
        "        # Back prop\n",
        "        loss.backward()\n",
        "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
        "        # within a healthy range\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = dim_)\n",
        "        # Gradient descent step\n",
        "        optimizer.step()\n",
        "    correct_pred, total_words, correct_pred = 0, len(val_X), 0\n",
        "    model.eval()\n",
        "    for i in range(total_words):\n",
        "\n",
        "        decoded_sentence,_ = beam_findGR(model,val_X[i], 10,input_char_index, output_char_index, reverse_input_char_index, reverse_target_char_index, \n",
        "                                         max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens, num_decoder_tokens,3,device)\n",
        "        if decoded_sentence == val_Y[i][dim_:-1]:\n",
        "            correct_pred = correct_pred + 1\n",
        "\n",
        "    print(correct_pred / total_words) #test_accuracy = correct_pred / total_words\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_words, correct_pred = len(test_X), 0\n",
        "input, correct, decoded, ex = [], [], [], []\n",
        "counttrue, countfalse = 0 , 0\n",
        "np.random.seed(10)"
      ],
      "metadata": {
        "id": "2M4Uqi59dQ-L"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(total_words):\n",
        "\n",
        "    decoded_sentence,_ = beam_findGR(model,test_X[i],10, input_char_index, output_char_index, reverse_input_char_index, reverse_target_char_index, \n",
        "                        max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens, num_decoder_tokens,1,device)\n",
        "    if decoded_sentence == test_Y[i][dim_:-1]:\n",
        "            correct_pred = correct_pred + 1\n",
        "\n",
        "print(\"Test Accuracy is :\") #test_accuracy = correct_pred / total_words\n",
        "print(correct_pred / total_words)\n"
      ],
      "metadata": {
        "id": "1RA6cru0jojZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975ab181-4e15-44ee-e510-208b7864455a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy is :\n",
            "0.484130859375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(total_words):\n",
        "    npos, pos = -1, 1\n",
        "    decoded_sentence,_ = beam_findGR(model,test_X[index],10, input_char_index, output_char_index, reverse_input_char_index, reverse_target_char_index, \n",
        "                                      max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens, num_decoder_tokens,1,device)\n",
        "    if decoded_sentence != test_Y[index][dim_: -1]:\n",
        "            countfalse = countfalse + 1\n",
        "            ex.append(\"No\")\n",
        "    else:\n",
        "            counttrue = counttrue + 1\n",
        "            ex.append(\"Yes\")     \n",
        "    #print(decoded_sentence)  \n",
        "    decoded_output, real_input = decoded_sentence, test_X[index]\n",
        "    real_output = test_Y[index][dim_: -1]\n",
        "    decoded.append(decoded_output)\n",
        "    input.append(real_input)\n",
        "    correct.append(real_output)\n",
        "\n",
        "grid = {'Input_Word': input, 'Decoded_Output' : decoded, 'True_Output' : correct, \"Match Result\" : ex}\n",
        "_path = '/content/drive/MyDrive/aksharantar_dataset/tel/att_predict.csv'\n",
        "df = pd.DataFrame(grid)\n",
        "df.to_csv(_path, index = False, header = True)\n",
        "pd.DataFrame(grid)"
      ],
      "metadata": {
        "id": "zM9kDXLw4lky",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "06e23785-cf11-4d18-a47a-24fd5e8e07c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Input_Word Decoded_Output  True_Output Match Result\n",
              "0        vithananni     వితానాన్ని  విత్తనాన్ని           No\n",
              "1      prayaanikulu    ప్రయాణికులు  ప్రయాణికులు          Yes\n",
              "2            hassan         హసాసన్         హసన్           No\n",
              "3          pakshala          పక్షల       పక్షాల           No\n",
              "4           goutham           గౌతం        గౌతమ్           No\n",
              "...             ...            ...          ...          ...\n",
              "4091          kukie           కుకీ         కుకీ          Yes\n",
              "4092  mosaginchadam      మొసగించడం    మోసగించడం           No\n",
              "4093    telamgaanha        తెలంగాణ      తెలంగాణ          Yes\n",
              "4094          patel         పాటెల్        పటేల్           No\n",
              "4095           peda           పెడా          పేడ           No\n",
              "\n",
              "[4096 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec2d2076-4b54-4c70-83bc-d2fe472ae8c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input_Word</th>\n",
              "      <th>Decoded_Output</th>\n",
              "      <th>True_Output</th>\n",
              "      <th>Match Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vithananni</td>\n",
              "      <td>వితానాన్ని</td>\n",
              "      <td>విత్తనాన్ని</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>prayaanikulu</td>\n",
              "      <td>ప్రయాణికులు</td>\n",
              "      <td>ప్రయాణికులు</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hassan</td>\n",
              "      <td>హసాసన్</td>\n",
              "      <td>హసన్</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pakshala</td>\n",
              "      <td>పక్షల</td>\n",
              "      <td>పక్షాల</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>goutham</td>\n",
              "      <td>గౌతం</td>\n",
              "      <td>గౌతమ్</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>kukie</td>\n",
              "      <td>కుకీ</td>\n",
              "      <td>కుకీ</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>mosaginchadam</td>\n",
              "      <td>మొసగించడం</td>\n",
              "      <td>మోసగించడం</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>telamgaanha</td>\n",
              "      <td>తెలంగాణ</td>\n",
              "      <td>తెలంగాణ</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>patel</td>\n",
              "      <td>పాటెల్</td>\n",
              "      <td>పటేల్</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>peda</td>\n",
              "      <td>పెడా</td>\n",
              "      <td>పేడ</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4096 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec2d2076-4b54-4c70-83bc-d2fe472ae8c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec2d2076-4b54-4c70-83bc-d2fe472ae8c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec2d2076-4b54-4c70-83bc-d2fe472ae8c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}